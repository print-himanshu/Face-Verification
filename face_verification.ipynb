{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('deep_learning': conda)",
   "metadata": {
    "interpreter": {
     "hash": "58f0689e023c01f6db0c24d484c62254b450cae836834f0c7d79a759a2144342"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.__version__ is 2.1.0\n",
      "tf.keras.__version__ is: 2.2.4-tf\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as tfback\n",
    "\n",
    "print(\"tf.__version__ is\", tf.__version__)\n",
    "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
    "\n",
    "def _get_available_gpus():\n",
    "    \"\"\"Get a list of available gpu devices (formatted as strings).\n",
    "\n",
    "    # Returns\n",
    "        A list of available GPU devices.\n",
    "    \"\"\"\n",
    "    #global _LOCAL_DEVICES\n",
    "    if tfback._LOCAL_DEVICES is None:\n",
    "        devices = tf.config.list_logical_devices()\n",
    "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
    "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
    "\n",
    "tfback._get_available_gpus = _get_available_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ZeroPadding2D, Activation, MaxPooling2D, Input\n",
    "from tensorflow.keras.layers import Input, Lambda, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(tensors, axis = -1):\n",
    "    if axis < 0:\n",
    "        axis = axis % len(tensor[0].get_shape())\n",
    "    return tf.concat(tensors, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block_1a(X):\n",
    "\n",
    "    X_3x3 = Conv2D(filters = 96, kernel_size = (1,1), data_format = 'channels_first', name = \"inception_3a_3x3_conv1\")(X)\n",
    "    X_3x3 = BatchNormalization(axis = 1, epsilon = 0.00001, name = 'inception_3a_3x3_bn1')(X_3x3)\n",
    "    X_3x3 = Activation(\"relu\")(X_3x3)\n",
    "    X_3x3 = ZeroPadding2D(padding = (1,1), data_format = 'channels_first')(X_3x3)\n",
    "    X_3x3 = Conv2D(filters = 128, kernel_size = (3,3), data_format = 'channels_first', name=  \"inception_3a_3x3_conv2\")(X_3x3)\n",
    "    X_3x3 = BatchNormalization(axis = 1 , epsilon = 0.00001, name = 'inception_3a_3x3_bn2')(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "\n",
    "    X_5x5 = Conv2D(filters = 16, kernel_size = (1,1), data_format = 'channels_first', name = \"inception_3a_5x5_conv1\")(X)\n",
    "    X_5x5 = BatchNormalization(axis = 1, epsilon = 0.00001, name = 'inception_3a_5x5_bn1')(X_5x5)\n",
    "    X_5x5 = Activation(\"relu\")(X_5x5)\n",
    "    X_5x5 = ZeroPadding2D(padding = (2,2), data_format = 'channels_first')(X_5x5)\n",
    "    X_5x5 = Conv2D(filters = 32, kernel_size = (5,5), data_format = 'channels_first', name=  \"inception_3a_5x5_conv2\")(X_5x5)\n",
    "    X_5x5 = BatchNormalization(axis = 1 , epsilon = 0.00001, name = 'inception_3a_5x5_bn2')(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "    \n",
    "    X_pool = MaxPooling2D(pool_size = 3, strides = 2, data_format= 'channels_first')(X)\n",
    "    X_pool = Conv2D(filters = 32, kernel_size = (1,1), data_format = 'channels_first',name = 'inception_3a_pool_conv')(X_pool)\n",
    "    X_pool = BatchNormalization(axis = 1, epsilon =0.00001, name= 'inception_3a_pool_bn')(X_pool)\n",
    "    X_pool = Activation(\"relu\")(X_pool)\n",
    "    X_pool = ZeroPadding2D(padding = ((3,4),(3,4)), data_format = \"channels_first\")(X_pool)\n",
    "\n",
    "    X_1x1 = Conv2D(filters = 64, kernel_size = (1,1), data_format= 'channels_first', name= 'inception_3a_1x1_conv')(X)\n",
    "    X_1x1 = BatchNormalization(axis = 1, epsilon = 0.00001, name= 'inception_3a_1x1_bn')(X_1x1)\n",
    "    X_1x1 = Activation('relu')(X_1x1)\n",
    "\n",
    "\n",
    "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis = 1)\n",
    "\n",
    "    return inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_block_1b(X):\n",
    "    X_3x3 = Conv2D(filters = 96, kernel_size = (1,1), data_format = 'channels_first', name = \"inception_3b_3x3_conv1\")(X)\n",
    "    X_3x3 = BatchNormalization(axis = 1, epsilon = 0.00001, name = 'inception_3b_3x3_bn1')(X_3x3)\n",
    "    X_3x3 = Activation(\"relu\")(X_3x3)\n",
    "    X_3x3 = ZeroPadding2D(padding = (1,1), data_format = 'channels_first')(X_3x3)\n",
    "    X_3x3 = Conv2D(filters = 128, kernel_size = (3,3), data_format = 'channels_first', name=  \"inception_3b_3x3_conv2\")(X_3x3)\n",
    "    X_3x3 = BatchNormalization(axis = 1 , epsilon = 0.00001, name = 'inception_3b_3x3_bn2')(X_3x3)\n",
    "    X_3x3 = Activation('relu')(X_3x3)\n",
    "    \n",
    "    X_5x5 = Conv2D(filters = 32, kernel_size = (1,1), data_format = 'channels_first', name = \"inception_3b_5x5_conv1\")(X)\n",
    "    X_5x5 = BatchNormalization(axis = 1, epsilon = 0.00001, name = 'inception_3b_5x5_bn1')(X_5x5)\n",
    "    X_5x5 = Activation(\"relu\")(X_5x5)\n",
    "    X_5x5 = ZeroPadding2D(padding = (2,2), data_format = 'channels_first')(X_5x5)\n",
    "    X_5x5 = Conv2D(filters = 64, kernel_size = (5,5), data_format = 'channels_first', name=  \"inception_3b_5x5_conv2\")(X_5x5)\n",
    "    X_5x5 = BatchNormalization(axis = 1 , epsilon = 0.00001, name = 'inception_3b_5x5_bn2')(X_5x5)\n",
    "    X_5x5 = Activation('relu')(X_5x5)\n",
    "\n",
    "    X_pool = AveragePooling2D(pool_size = (3,3), strides = (3,3), data_format= 'channels_first')(X)\n",
    "    X_pool = Conv2D(filters = 64, kernel_size = (1,1), data_format = 'channels_first',name = 'inception_3b_pool_conv')(X_pool)\n",
    "    X_pool = BatchNormalization(axis = 1, epsilon =0.00001, name= 'inception_3b_pool_bn')(X_pool)\n",
    "    X_pool = Activation(\"relu\")(X_pool)\n",
    "    X_pool = ZeroPadding2D(padding = (4,4), data_format = \"channels_first\")(X_pool)\n",
    "\n",
    "    X_1x1 = Conv2D(filters = 64, kernel_size = (1,1), data_format= 'channels_first', name= 'inception_3b_1x1_conv')(X)\n",
    "    X_1x1 = BatchNormalization(axis = 1, epsilon = 0.00001, name= 'inception_3b_1x1_bn')(X_1x1)\n",
    "    X_1x1 = Activation('relu')(X_1x1)\n",
    "\n",
    "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis = 1)\n",
    "    return inception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_bn(x,\n",
    "              layer=None,\n",
    "              cv1_out=None,\n",
    "              cv1_filter=(1, 1),\n",
    "              cv1_strides=(1, 1),\n",
    "              cv2_out=None,\n",
    "              cv2_filter=(3, 3),\n",
    "              cv2_strides=(1, 1),\n",
    "              padding=None):\n",
    "    num = '' if cv2_out == None else '1'\n",
    "    tensor = Conv2D(cv1_out, cv1_filter, strides=cv1_strides, data_format='channels_first', name=layer+'_conv'+num)(x)\n",
    "    tensor = BatchNormalization(axis=1, epsilon=0.00001, name=layer+'_bn'+num)(tensor)\n",
    "    tensor = Activation('relu')(tensor)\n",
    "\n",
    "    if padding == None:\n",
    "        return tensor\n",
    "    tensor = ZeroPadding2D(padding=padding, data_format='channels_first')(tensor)\n",
    "\n",
    "    if cv2_out == None:\n",
    "        return tensor\n",
    "    tensor = Conv2D(cv2_out, cv2_filter, strides=cv2_strides, data_format='channels_first', name=layer+'_conv'+'2')(tensor)\n",
    "    tensor = BatchNormalization(axis=1, epsilon=0.00001, name=layer+'_bn'+'2')(tensor)\n",
    "    tensor = Activation('relu')(tensor)\n",
    "\n",
    "    return tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def inception_block_1c(X):\n",
    "    X_3x3 = conv2d_bn(X,\n",
    "                           layer='inception_3c_3x3',\n",
    "                           cv1_out=128,\n",
    "                           cv1_filter=(1, 1),\n",
    "                           cv2_out=256,\n",
    "                           cv2_filter=(3, 3),\n",
    "                           cv2_strides=(2, 2),\n",
    "                           padding=(1, 1))\n",
    "\n",
    "    X_5x5 = conv2d_bn(X,\n",
    "                           layer='inception_3c_5x5',\n",
    "                           cv1_out=32,\n",
    "                           cv1_filter=(1, 1),\n",
    "                           cv2_out=64,\n",
    "                           cv2_filter=(5, 5),\n",
    "                           cv2_strides=(2, 2),\n",
    "                           padding=(2, 2))\n",
    "\n",
    "    X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
    "\n",
    "    X_pool = ZeroPadding2D(padding=((0, 1), (0, 1)), data_format='channels_first')(X_pool)\n",
    "\n",
    "\n",
    "    inception = concatenate([X_3x3, X_5x5, X_pool], axis=1)\n",
    "\n",
    "    return inception\n",
    "\n",
    "def inception_block_2a(X):\n",
    "    X_3x3 = conv2d_bn(X,\n",
    "                           layer='inception_4a_3x3',\n",
    "                           cv1_out=96,\n",
    "                           cv1_filter=(1, 1),\n",
    "                           cv2_out=192,\n",
    "                           cv2_filter=(3, 3),\n",
    "                           cv2_strides=(1, 1),\n",
    "                           padding=(1, 1))\n",
    "    X_5x5 = conv2d_bn(X,\n",
    "                           layer='inception_4a_5x5',\n",
    "                           cv1_out=32,\n",
    "                           cv1_filter=(1, 1),\n",
    "                           cv2_out=64,\n",
    "                           cv2_filter=(5, 5),\n",
    "                           cv2_strides=(1, 1),\n",
    "                           padding=(2, 2))\n",
    "\n",
    "    X_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(X)\n",
    "\n",
    "    X_pool = conv2d_bn(X_pool,\n",
    "                           layer='inception_4a_pool',\n",
    "                           cv1_out=128,\n",
    "                           cv1_filter=(1, 1),\n",
    "                           padding=(2, 2))\n",
    "\n",
    "    X_1x1 = conv2d_bn(X,\n",
    "                           layer='inception_4a_1x1',\n",
    "                           cv1_out=256,\n",
    "                           cv1_filter=(1, 1))\n",
    "\n",
    "    inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=1)\n",
    "\n",
    "\n",
    "    return inception\n",
    "\n",
    "def inception_block_2b(X):\n",
    "    #inception4e\n",
    "    X_3x3 = conv2d_bn(X,\n",
    "                           layer='inception_4e_3x3',\n",
    "                           cv1_out=160,\n",
    "                           cv1_filter=(1, 1),\n",
    "                           cv2_out=256,\n",
    "                           cv2_filter=(3, 3),\n",
    "                           cv2_strides=(2, 2),\n",
    "                           padding=(1, 1))\n",
    "    X_5x5 = conv2d_bn(X,\n",
    "                           layer='inception_4e_5x5',\n",
    "                           cv1_out=64,\n",
    "                           cv1_filter=(1, 1),\n",
    "                           cv2_out=128,\n",
    "                           cv2_filter=(5, 5),\n",
    "                           cv2_strides=(2, 2),\n",
    "                           padding=(2, 2))\n",
    "    \n",
    "    X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
    "    X_pool = ZeroPadding2D(padding=((0, 1), (0, 1)), data_format='channels_first')(X_pool)\n",
    "\n",
    "    inception = concatenate([X_3x3, X_5x5, X_pool], axis=1)\n",
    "\n",
    "\n",
    "    return inception\n",
    "\n",
    "def inception_block_3a(X):\n",
    "    X_3x3 = conv2d_bn(X,\n",
    "                           layer='inception_5a_3x3',\n",
    "                           cv1_out=96,\n",
    "                           cv1_filter=(1, 1),\n",
    "                           cv2_out=384,\n",
    "                           cv2_filter=(3, 3),\n",
    "                           cv2_strides=(1, 1),\n",
    "                           padding=(1, 1))\n",
    "    X_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3), data_format='channels_first')(X)\n",
    "    X_pool = conv2d_bn(X_pool,\n",
    "                           layer='inception_5a_pool',\n",
    "                           cv1_out=96,\n",
    "                           cv1_filter=(1, 1),\n",
    "                           padding=(1, 1))\n",
    "    X_1x1 = conv2d_bn(X,\n",
    "                           layer='inception_5a_1x1',\n",
    "                           cv1_out=256,\n",
    "                           cv1_filter=(1, 1))\n",
    "\n",
    "    inception = concatenate([X_3x3, X_pool, X_1x1], axis=1)\n",
    "\n",
    "\n",
    "    return inception\n",
    "\n",
    "def inception_block_3b(X):\n",
    "    X_3x3 = conv2d_bn(X,\n",
    "                           layer='inception_5b_3x3',\n",
    "                           cv1_out=96,\n",
    "                           cv1_filter=(1, 1),\n",
    "                           cv2_out=384,\n",
    "                           cv2_filter=(3, 3),\n",
    "                           cv2_strides=(1, 1),\n",
    "                           padding=(1, 1))\n",
    "    X_pool = MaxPooling2D(pool_size=3, strides=2, data_format='channels_first')(X)\n",
    "    X_pool = conv2d_bn(X_pool,\n",
    "                           layer='inception_5b_pool',\n",
    "                           cv1_out=96,\n",
    "                           cv1_filter=(1, 1))\n",
    "    X_pool = ZeroPadding2D(padding=(1, 1), data_format='channels_first')(X_pool)\n",
    "\n",
    "\n",
    "    X_1x1 = conv2d_bn(X,\n",
    "                           layer='inception_5b_1x1',\n",
    "                           cv1_out=256,\n",
    "                           cv1_filter=(1, 1))\n",
    "    inception = concatenate([X_3x3, X_pool, X_1x1], axis=1)\n",
    "\n",
    "    return inception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faceRecoModel(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the Inception model used for FaceNet\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "        \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3), data_format=\"channels_first\")(X_input)\n",
    "\n",
    "    # First Block\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', data_format=\"channels_first\")(X)\n",
    "    X = BatchNormalization(axis = 1, name = 'bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Zero-Padding + MAXPOOL\n",
    "    X = ZeroPadding2D((1, 1), data_format='channels_first')(X)\n",
    "\n",
    "    X = MaxPooling2D((3, 3), strides = 2, data_format='channels_first')(X)\n",
    "\n",
    "    # Second Block\n",
    "    X = Conv2D(64, (1, 1), strides = (1, 1), name = 'conv2',data_format='channels_first' )(X)\n",
    "    X = BatchNormalization(axis = 1, epsilon=0.00001, name = 'bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    \n",
    "    # Zero-Padding + MAXPOOL\n",
    "    X = ZeroPadding2D((1, 1), data_format='channels_first')(X)\n",
    "\n",
    "\n",
    "    # Second Block\n",
    "    X = Conv2D(192, (3, 3), strides = (1, 1), name = 'conv3', data_format='channels_first')(X)\n",
    "    X = BatchNormalization(axis = 1, epsilon=0.00001, name = 'bn3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Zero-Padding + MAXPOOL\n",
    "    X = ZeroPadding2D((1, 1), data_format='channels_first')(X)\n",
    "    X = MaxPooling2D(pool_size = 3, strides = 2, data_format= 'channels_first')(X)\n",
    "    \n",
    "    # Inception 1: a/b/c\n",
    "    X = inception_block_1a(X)\n",
    "    X = inception_block_1b(X)\n",
    "    X = inception_block_1c(X)\n",
    "    \n",
    "    # Inception 2: a/b\n",
    "    X = inception_block_2a(X)\n",
    "    X = inception_block_2b(X)\n",
    "    \n",
    "    # Inception 3: a/b\n",
    "    X = inception_block_3a(X)\n",
    "    X = inception_block_3b(X)\n",
    "    \n",
    "    # Top layer\n",
    "    X = AveragePooling2D(pool_size=(3, 3), strides=(1, 1), data_format='channels_first')(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(128, name='dense_layer')(X)\n",
    "\n",
    "    \n",
    "    # L2 normalization\n",
    "    X = Lambda(lambda  x: K.l2_normalize(x,axis=1))(X)\n",
    "\n",
    "    # Create model instance\n",
    "    model = Model(inputs = X_input, outputs = X, name='FaceRecoModel')\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total Params: 3743280\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Params: {FRmodel.count_params()}\")"
   ]
  },
  {
   "source": [
    "def triplet_loss(y_true, y_pred , alpha = 0.2):\n",
    "    \n",
    "    anchor , positive , negative  = y_pred[0], y_pred[1], y_pred[2]\n",
    "\n",
    "    pos_dis = tf.square(tf.norm(tf.subtract(anchor, positive) , axis = -1))\n",
    "    neg_dis = tf.square(tf.norm(tf.subtract(anchor, negative) , axis = -1))\n",
    "    basic_loss = tf.add(tf.subtract(pos_dis , neg_dis) , alpha)    \n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss, 0.0))\n",
    "\n",
    "    return loss"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "with tf.compat.v1.Session() as test:\n",
    "    tf.compat.v1.set_random_seed(1)\n",
    "    y_true = (None, None, None)\n",
    "    y_pred = ( tf.compat.v1.random_normal([3,128], mean = 6, stddev= 0.1, seed = 1),\n",
    "               tf.compat.v1.random_normal([3,128], mean = 1 , stddev= 1, seed = 1),\n",
    "               tf.compat.v1.random_normal([3,128], mean = 3, stddev= 4, seed = 1))\n",
    "\n",
    "    loss = triplet_loss(y_true, y_pred)\n",
    "    print(\"Loss = \"+str(loss.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel.compile(optimizer= tf.keras.optimizers.Adam(),\n",
    "                loss= triplet_loss,\n",
    "                metrics= ['accuracy'])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = [\n",
    "  'conv1', 'bn1', 'conv2', 'bn2', 'conv3', 'bn3',\n",
    "  'inception_3a_1x1_conv', 'inception_3a_1x1_bn',\n",
    "  'inception_3a_pool_conv', 'inception_3a_pool_bn',\n",
    "  'inception_3a_5x5_conv1', 'inception_3a_5x5_conv2', 'inception_3a_5x5_bn1', 'inception_3a_5x5_bn2',\n",
    "  'inception_3a_3x3_conv1', 'inception_3a_3x3_conv2', 'inception_3a_3x3_bn1', 'inception_3a_3x3_bn2',\n",
    "  'inception_3b_3x3_conv1', 'inception_3b_3x3_conv2', 'inception_3b_3x3_bn1', 'inception_3b_3x3_bn2',\n",
    "  'inception_3b_5x5_conv1', 'inception_3b_5x5_conv2', 'inception_3b_5x5_bn1', 'inception_3b_5x5_bn2',\n",
    "  'inception_3b_pool_conv', 'inception_3b_pool_bn',\n",
    "  'inception_3b_1x1_conv', 'inception_3b_1x1_bn',\n",
    "  'inception_3c_3x3_conv1', 'inception_3c_3x3_conv2', 'inception_3c_3x3_bn1', 'inception_3c_3x3_bn2',\n",
    "  'inception_3c_5x5_conv1', 'inception_3c_5x5_conv2', 'inception_3c_5x5_bn1', 'inception_3c_5x5_bn2',\n",
    "  'inception_4a_3x3_conv1', 'inception_4a_3x3_conv2', 'inception_4a_3x3_bn1', 'inception_4a_3x3_bn2',\n",
    "  'inception_4a_5x5_conv1', 'inception_4a_5x5_conv2', 'inception_4a_5x5_bn1', 'inception_4a_5x5_bn2',\n",
    "  'inception_4a_pool_conv', 'inception_4a_pool_bn',\n",
    "  'inception_4a_1x1_conv', 'inception_4a_1x1_bn',\n",
    "  'inception_4e_3x3_conv1', 'inception_4e_3x3_conv2', 'inception_4e_3x3_bn1', 'inception_4e_3x3_bn2',\n",
    "  'inception_4e_5x5_conv1', 'inception_4e_5x5_conv2', 'inception_4e_5x5_bn1', 'inception_4e_5x5_bn2',\n",
    "  'inception_5a_3x3_conv1', 'inception_5a_3x3_conv2', 'inception_5a_3x3_bn1', 'inception_5a_3x3_bn2',\n",
    "  'inception_5a_pool_conv', 'inception_5a_pool_bn',\n",
    "  'inception_5a_1x1_conv', 'inception_5a_1x1_bn',\n",
    "  'inception_5b_3x3_conv1', 'inception_5b_3x3_conv2', 'inception_5b_3x3_bn1', 'inception_5b_3x3_bn2',\n",
    "  'inception_5b_pool_conv', 'inception_5b_pool_bn',\n",
    "  'inception_5b_1x1_conv', 'inception_5b_1x1_bn',\n",
    "  'dense_layer'\n",
    "]\n",
    "\n",
    "conv_shape = {\n",
    "  'conv1': [64, 3, 7, 7],\n",
    "  'conv2': [64, 64, 1, 1],\n",
    "  'conv3': [192, 64, 3, 3],\n",
    "  'inception_3a_1x1_conv': [64, 192, 1, 1],\n",
    "  'inception_3a_pool_conv': [32, 192, 1, 1],\n",
    "  'inception_3a_5x5_conv1': [16, 192, 1, 1],\n",
    "  'inception_3a_5x5_conv2': [32, 16, 5, 5],\n",
    "  'inception_3a_3x3_conv1': [96, 192, 1, 1],\n",
    "  'inception_3a_3x3_conv2': [128, 96, 3, 3],\n",
    "  'inception_3b_3x3_conv1': [96, 256, 1, 1],\n",
    "  'inception_3b_3x3_conv2': [128, 96, 3, 3],\n",
    "  'inception_3b_5x5_conv1': [32, 256, 1, 1],\n",
    "  'inception_3b_5x5_conv2': [64, 32, 5, 5],\n",
    "  'inception_3b_pool_conv': [64, 256, 1, 1],\n",
    "  'inception_3b_1x1_conv': [64, 256, 1, 1],\n",
    "  'inception_3c_3x3_conv1': [128, 320, 1, 1],\n",
    "  'inception_3c_3x3_conv2': [256, 128, 3, 3],\n",
    "  'inception_3c_5x5_conv1': [32, 320, 1, 1],\n",
    "  'inception_3c_5x5_conv2': [64, 32, 5, 5],\n",
    "  'inception_4a_3x3_conv1': [96, 640, 1, 1],\n",
    "  'inception_4a_3x3_conv2': [192, 96, 3, 3],\n",
    "  'inception_4a_5x5_conv1': [32, 640, 1, 1,],\n",
    "  'inception_4a_5x5_conv2': [64, 32, 5, 5],\n",
    "  'inception_4a_pool_conv': [128, 640, 1, 1],\n",
    "  'inception_4a_1x1_conv': [256, 640, 1, 1],\n",
    "  'inception_4e_3x3_conv1': [160, 640, 1, 1],\n",
    "  'inception_4e_3x3_conv2': [256, 160, 3, 3],\n",
    "  'inception_4e_5x5_conv1': [64, 640, 1, 1],\n",
    "  'inception_4e_5x5_conv2': [128, 64, 5, 5],\n",
    "  'inception_5a_3x3_conv1': [96, 1024, 1, 1],\n",
    "  'inception_5a_3x3_conv2': [384, 96, 3, 3],\n",
    "  'inception_5a_pool_conv': [96, 1024, 1, 1],\n",
    "  'inception_5a_1x1_conv': [256, 1024, 1, 1],\n",
    "  'inception_5b_3x3_conv1': [96, 736, 1, 1],\n",
    "  'inception_5b_3x3_conv2': [384, 96, 3, 3],\n",
    "  'inception_5b_pool_conv': [96, 736, 1, 1],\n",
    "  'inception_5b_1x1_conv': [256, 736, 1, 1],\n",
    "}\n",
    "\n",
    "\n",
    "def load_weights():\n",
    "    dirPath = 'helper/weights'\n",
    "    fileNames = filter(lambda f: not f.startswith('.'), os.listdir(dirPath))\n",
    "    paths = {}\n",
    "    weights_dict = {}\n",
    "\n",
    "    for n in fileNames:\n",
    "        paths[n.replace('.csv','')] = dirPath + '/' + n\n",
    "\n",
    "    for name in WEIGHTS:\n",
    "        if 'conv' in name:\n",
    "            conv_w = np.genfromtxt(paths[name + \"_w\"], delimiter= ',', dtype = None)\n",
    "            conv_b = np.genfromtxt(paths[name + '_b'], delimiter = ',', dtype = None)\n",
    "            \n",
    "            conv_w = np.reshape(conv_w, conv_shape[name])\n",
    "            conv_w = np.transpose(conv_w, (2,3,1,0))\n",
    "            weights_dict[name] = [conv_w, conv_b]\n",
    "        elif 'bn' in name:\n",
    "            bn_w = np.genfromtxt(paths[name + '_w'], delimiter=',', dtype=None)\n",
    "            bn_b = np.genfromtxt(paths[name + '_b'], delimiter=',', dtype=None)\n",
    "            bn_m = np.genfromtxt(paths[name + '_m'], delimiter=',', dtype=None)\n",
    "            bn_v = np.genfromtxt(paths[name + '_v'], delimiter=',', dtype=None)\n",
    "            weights_dict[name] = [bn_w, bn_b, bn_m, bn_v]\n",
    "        elif 'dense' in name:\n",
    "            dense_w = np.genfromtxt(dirPath+'/dense_w.csv', delimiter=',', dtype=None)\n",
    "            dense_w = np.reshape(dense_w, (128, 736))\n",
    "            dense_w = np.transpose(dense_w, (1, 0))\n",
    "            dense_b = np.genfromtxt(dirPath+'/dense_b.csv', delimiter=',', dtype=None)\n",
    "            weights_dict[name] = [dense_w, dense_b]\n",
    "    \n",
    "    return weights_dict\n",
    "\n",
    "def load_weights_from_FaceNet(FRmodel):\n",
    "    # Load weights from csv files (which was exported from Openface torch model)\n",
    "    weights = WEIGHTS\n",
    "    weights_dict = load_weights()\n",
    "\n",
    "    # Set layer weights of the model\n",
    "    for name in weights:\n",
    "        if FRmodel.get_layer(name) != None:\n",
    "            FRmodel.get_layer(name).set_weights(weights_dict[name])\n",
    "        elif model.get_layer(name) != None:\n",
    "            model.get_layer(name).set_weights(weights_dict[name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def img_to_encoding(image_path , model):\n",
    "    img1 = cv2.imread(image_path, 1)\n",
    "    img = img1[...,::-1]\n",
    "    img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"danielle\"] = img_to_encoding(\"helper/images/danielle.png\", FRmodel)\n",
    "database[\"younes\"] = img_to_encoding(\"helper/images/younes.jpg\", FRmodel)\n",
    "database[\"tian\"] = img_to_encoding(\"helper/images/tian.jpg\", FRmodel)\n",
    "database[\"andrew\"] = img_to_encoding(\"helper/images/andrew.jpg\", FRmodel)\n",
    "database[\"kian\"] = img_to_encoding(\"helper/images/kian.jpg\", FRmodel)\n",
    "database[\"dan\"] = img_to_encoding(\"helper/images/dan.jpg\", FRmodel)\n",
    "database[\"sebastiano\"] = img_to_encoding(\"helper/images/sebastiano.jpg\", FRmodel)\n",
    "database[\"bertrand\"] = img_to_encoding(\"helper/images/bertrand.jpg\", FRmodel)\n",
    "database[\"kevin\"] = img_to_encoding(\"helper/images/kevin.jpg\", FRmodel)\n",
    "database[\"felix\"] = img_to_encoding(\"helper/images/felix.jpg\", FRmodel)\n",
    "database[\"benoit\"] = img_to_encoding(\"helper/images/benoit.jpg\", FRmodel)\n",
    "database[\"arnaud\"] = img_to_encoding(\"helper/images/arnaud.jpg\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(image_path, identity, database, model):\n",
    "\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    dist = np.linalg.norm(encoding - database[identity])\n",
    "    \n",
    "    if dist < 0.7:\n",
    "        print(\"It's \" + str(identity) + \", welcome in!\")\n",
    "        door_open = True\n",
    "    else:\n",
    "        print(\"It's not \" + str(identity) + \", please go away\")\n",
    "        door_open = False\n",
    "        \n",
    "\n",
    "    return dist, door_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It's younes, welcome in!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.6593843, True)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "verify(\"helper/images/camera_0.jpg\", \"younes\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It's not kian, please go away\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.8622578, False)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "verify(\"helper/images/camera_2.jpg\", \"kian\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def who_is_it(image_path, database, model):\n",
    "\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "\n",
    "    min_dist = 100\n",
    "    \n",
    "    for (name, db_enc) in database.items():\n",
    "        dist, _ = verify(image_path, name, database, model)\n",
    "\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "            \n",
    "    if min_dist > 0.7:\n",
    "        print(\"Not in the database.\")\n",
    "    else:\n",
    "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "        \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "It's not danielle, please go away\nIt's younes, welcome in!\nIt's not tian, please go away\nIt's not andrew, please go away\nIt's not kian, please go away\nIt's not dan, please go away\nIt's not sebastiano, please go away\nIt's not bertrand, please go away\nIt's not kevin, please go away\nIt's not felix, please go away\nIt's not benoit, please go away\nIt's not arnaud, please go away\nit's younes, the distance is 0.6593843\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.6593843, 'younes')"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "who_is_it(\"helper/images/camera_0.jpg\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}